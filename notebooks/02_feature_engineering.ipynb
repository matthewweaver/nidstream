{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1b611aa",
   "metadata": {},
   "source": [
    "# Feature Engineering for Network Intrusion Detection\n",
    "\n",
    "This notebook performs feature engineering on the BCCC-CSE-CIC-IDS2018 dataset.\n",
    "\n",
    "## Objectives:\n",
    "1. Load and preprocess raw network flow data\n",
    "2. Handle missing values and outliers\n",
    "3. Create derived features\n",
    "4. Encode categorical variables\n",
    "5. Scale numerical features\n",
    "6. Handle class imbalance\n",
    "7. Save processed features for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e7f6d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22f5cc4",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4124e2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 289,799 records\n",
      "Number of features: 323\n",
      "\n",
      "Columns: ['flow_id', 'timestamp', 'src_ip', 'src_port', 'dst_ip', 'dst_port', 'protocol', 'duration', 'packets_count', 'fwd_packets_count', 'bwd_packets_count', 'total_payload_bytes', 'fwd_total_payload_bytes', 'bwd_total_payload_bytes', 'payload_bytes_max', 'payload_bytes_min', 'payload_bytes_mean', 'payload_bytes_std', 'payload_bytes_variance', 'payload_bytes_median', 'payload_bytes_skewness', 'payload_bytes_cov', 'payload_bytes_mode', 'fwd_payload_bytes_max', 'fwd_payload_bytes_min', 'fwd_payload_bytes_mean', 'fwd_payload_bytes_std', 'fwd_payload_bytes_variance', 'fwd_payload_bytes_median', 'fwd_payload_bytes_skewness', 'fwd_payload_bytes_cov', 'fwd_payload_bytes_mode', 'bwd_payload_bytes_max', 'bwd_payload_bytes_min', 'bwd_payload_bytes_mean', 'bwd_payload_bytes_std', 'bwd_payload_bytes_variance', 'bwd_payload_bytes_median', 'bwd_payload_bytes_skewness', 'bwd_payload_bytes_cov', 'bwd_payload_bytes_mode', 'total_header_bytes', 'max_header_bytes', 'min_header_bytes', 'mean_header_bytes', 'std_header_bytes', 'median_header_bytes', 'skewness_header_bytes', 'cov_header_bytes', 'mode_header_bytes', 'variance_header_bytes', 'fwd_total_header_bytes', 'fwd_max_header_bytes', 'fwd_min_header_bytes', 'fwd_mean_header_bytes', 'fwd_std_header_bytes', 'fwd_median_header_bytes', 'fwd_skewness_header_bytes', 'fwd_cov_header_bytes', 'fwd_mode_header_bytes', 'fwd_variance_header_bytes', 'bwd_total_header_bytes', 'bwd_max_header_bytes', 'bwd_min_header_bytes', 'bwd_mean_header_bytes', 'bwd_std_header_bytes', 'bwd_median_header_bytes', 'bwd_skewness_header_bytes', 'bwd_cov_header_bytes', 'bwd_mode_header_bytes', 'bwd_variance_header_bytes', 'fwd_avg_segment_size', 'bwd_avg_segment_size', 'avg_segment_size', 'fwd_init_win_bytes', 'bwd_init_win_bytes', 'active_min', 'active_max', 'active_mean', 'active_std', 'active_median', 'active_skewness', 'active_cov', 'active_mode', 'active_variance', 'idle_min', 'idle_max', 'idle_mean', 'idle_std', 'idle_median', 'idle_skewness', 'idle_cov', 'idle_mode', 'idle_variance', 'bytes_rate', 'fwd_bytes_rate', 'bwd_bytes_rate', 'packets_rate', 'bwd_packets_rate', 'fwd_packets_rate', 'down_up_rate', 'avg_fwd_bytes_per_bulk', 'avg_fwd_packets_per_bulk', 'avg_fwd_bulk_rate', 'avg_bwd_bytes_per_bulk', 'avg_bwd_packets_bulk_rate', 'avg_bwd_bulk_rate', 'fwd_bulk_state_count', 'fwd_bulk_total_size', 'fwd_bulk_per_packet', 'fwd_bulk_duration', 'bwd_bulk_state_count', 'bwd_bulk_total_size', 'bwd_bulk_per_packet', 'bwd_bulk_duration', 'fin_flag_counts', 'psh_flag_counts', 'urg_flag_counts', 'ece_flag_counts', 'syn_flag_counts', 'ack_flag_counts', 'cwr_flag_counts', 'rst_flag_counts', 'fwd_fin_flag_counts', 'fwd_psh_flag_counts', 'fwd_urg_flag_counts', 'fwd_ece_flag_counts', 'fwd_syn_flag_counts', 'fwd_ack_flag_counts', 'fwd_cwr_flag_counts', 'fwd_rst_flag_counts', 'bwd_fin_flag_counts', 'bwd_psh_flag_counts', 'bwd_urg_flag_counts', 'bwd_ece_flag_counts', 'bwd_syn_flag_counts', 'bwd_ack_flag_counts', 'bwd_cwr_flag_counts', 'bwd_rst_flag_counts', 'fin_flag_percentage_in_total', 'psh_flag_percentage_in_total', 'urg_flag_percentage_in_total', 'ece_flag_percentage_in_total', 'syn_flag_percentage_in_total', 'ack_flag_percentage_in_total', 'cwr_flag_percentage_in_total', 'rst_flag_percentage_in_total', 'fwd_fin_flag_percentage_in_total', 'fwd_psh_flag_percentage_in_total', 'fwd_urg_flag_percentage_in_total', 'fwd_ece_flag_percentage_in_total', 'fwd_syn_flag_percentage_in_total', 'fwd_ack_flag_percentage_in_total', 'fwd_cwr_flag_percentage_in_total', 'fwd_rst_flag_percentage_in_total', 'bwd_fin_flag_percentage_in_total', 'bwd_psh_flag_percentage_in_total', 'bwd_urg_flag_percentage_in_total', 'bwd_ece_flag_percentage_in_total', 'bwd_syn_flag_percentage_in_total', 'bwd_ack_flag_percentage_in_total', 'bwd_cwr_flag_percentage_in_total', 'bwd_rst_flag_percentage_in_total', 'fwd_fin_flag_percentage_in_fwd_packets', 'fwd_psh_flag_percentage_in_fwd_packets', 'fwd_urg_flag_percentage_in_fwd_packets', 'fwd_ece_flag_percentage_in_fwd_packets', 'fwd_syn_flag_percentage_in_fwd_packets', 'fwd_ack_flag_percentage_in_fwd_packets', 'fwd_cwr_flag_percentage_in_fwd_packets', 'fwd_rst_flag_percentage_in_fwd_packets', 'bwd_fin_flag_percentage_in_bwd_packets', 'bwd_psh_flag_percentage_in_bwd_packets', 'bwd_urg_flag_percentage_in_bwd_packets', 'bwd_ece_flag_percentage_in_bwd_packets', 'bwd_syn_flag_percentage_in_bwd_packets', 'bwd_ack_flag_percentage_in_bwd_packets', 'bwd_cwr_flag_percentage_in_bwd_packets', 'bwd_rst_flag_percentage_in_bwd_packets', 'packets_IAT_mean', 'packet_IAT_std', 'packet_IAT_max', 'packet_IAT_min', 'packet_IAT_total', 'packets_IAT_median', 'packets_IAT_skewness', 'packets_IAT_cov', 'packets_IAT_mode', 'packets_IAT_variance', 'fwd_packets_IAT_mean', 'fwd_packets_IAT_std', 'fwd_packets_IAT_max', 'fwd_packets_IAT_min', 'fwd_packets_IAT_total', 'fwd_packets_IAT_median', 'fwd_packets_IAT_skewness', 'fwd_packets_IAT_cov', 'fwd_packets_IAT_mode', 'fwd_packets_IAT_variance', 'bwd_packets_IAT_mean', 'bwd_packets_IAT_std', 'bwd_packets_IAT_max', 'bwd_packets_IAT_min', 'bwd_packets_IAT_total', 'bwd_packets_IAT_median', 'bwd_packets_IAT_skewness', 'bwd_packets_IAT_cov', 'bwd_packets_IAT_mode', 'bwd_packets_IAT_variance', 'subflow_fwd_packets', 'subflow_bwd_packets', 'subflow_fwd_bytes', 'subflow_bwd_bytes', 'delta_start', 'handshake_duration', 'handshake_state', 'min_bwd_packets_delta_time', 'max_bwd_packets_delta_time', 'mean_packets_delta_time', 'mode_packets_delta_time', 'variance_packets_delta_time', 'std_packets_delta_time', 'median_packets_delta_time', 'skewness_packets_delta_time', 'cov_packets_delta_time', 'mean_bwd_packets_delta_time', 'mode_bwd_packets_delta_time', 'variance_bwd_packets_delta_time', 'std_bwd_packets_delta_time', 'median_bwd_packets_delta_time', 'skewness_bwd_packets_delta_time', 'cov_bwd_packets_delta_time', 'min_fwd_packets_delta_time', 'max_fwd_packets_delta_time', 'mean_fwd_packets_delta_time', 'mode_fwd_packets_delta_time', 'variance_fwd_packets_delta_time', 'std_fwd_packets_delta_time', 'median_fwd_packets_delta_time', 'skewness_fwd_packets_delta_time', 'cov_fwd_packets_delta_time', 'min_packets_delta_len', 'max_packets_delta_len', 'mean_packets_delta_len', 'mode_packets_delta_len', 'variance_packets_delta_len', 'std_packets_delta_len', 'median_packets_delta_len', 'skewness_packets_delta_len', 'cov_packets_delta_len', 'min_bwd_packets_delta_len', 'max_bwd_packets_delta_len', 'mean_bwd_packets_delta_len', 'mode_bwd_packets_delta_len', 'variance_bwd_packets_delta_len', 'std_bwd_packets_delta_len', 'median_bwd_packets_delta_len', 'skewness_bwd_packets_delta_len', 'cov_bwd_packets_delta_len', 'min_fwd_packets_delta_len', 'max_fwd_packets_delta_len', 'mean_fwd_packets_delta_len', 'mode_fwd_packets_delta_len', 'variance_fwd_packets_delta_len', 'std_fwd_packets_delta_len', 'median_fwd_packets_delta_len', 'skewness_fwd_packets_delta_len', 'cov_fwd_packets_delta_len', 'min_header_bytes_delta_len', 'max_header_bytes_delta_len', 'mean_header_bytes_delta_len', 'mode_header_bytes_delta_len', 'variance_header_bytes_delta_len', 'std_header_bytes_delta_len', 'median_header_bytes_delta_len', 'skewness_header_bytes_delta_len', 'cov_header_bytes_delta_len', 'min_bwd_header_bytes_delta_len', 'max_bwd_header_bytes_delta_len', 'mean_bwd_header_bytes_delta_len', 'mode_bwd_header_bytes_delta_len', 'variance_bwd_header_bytes_delta_len', 'std_bwd_header_bytes_delta_len', 'median_bwd_header_bytes_delta_len', 'skewness_bwd_header_bytes_delta_len', 'cov_bwd_header_bytes_delta_len', 'min_fwd_header_bytes_delta_len', 'max_fwd_header_bytes_delta_len', 'mean_fwd_header_bytes_delta_len', 'mode_fwd_header_bytes_delta_len', 'variance_fwd_header_bytes_delta_len', 'std_fwd_header_bytes_delta_len', 'median_fwd_header_bytes_delta_len', 'skewness_fwd_header_bytes_delta_len', 'cov_fwd_header_bytes_delta_len', 'min_payload_bytes_delta_len', 'max_payload_bytes_delta_len', 'mean_payload_bytes_delta_len', 'mode_payload_bytes_delta_len', 'variance_payload_bytes_delta_len', 'std_payload_bytes_delta_len', 'median_payload_bytes_delta_len', 'skewness_payload_bytes_delta_len', 'cov_payload_bytes_delta_len', 'min_bwd_payload_bytes_delta_len', 'max_bwd_payload_bytes_delta_len', 'mean_bwd_payload_bytes_delta_len', 'mode_bwd_payload_bytes_delta_len', 'variance_bwd_payload_bytes_delta_len', 'std_bwd_payload_bytes_delta_len', 'median_bwd_payload_bytes_delta_len', 'skewness_bwd_payload_bytes_delta_len', 'cov_bwd_payload_bytes_delta_len', 'min_fwd_payload_bytes_delta_len', 'max_fwd_payload_bytes_delta_len', 'mean_fwd_payload_bytes_delta_len', 'mode_fwd_payload_bytes_delta_len', 'variance_fwd_payload_bytes_delta_len', 'std_fwd_payload_bytes_delta_len', 'median_fwd_payload_bytes_delta_len', 'skewness_fwd_payload_bytes_delta_len', 'cov_fwd_payload_bytes_delta_len', 'label']\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "project_root = Path().resolve()\n",
    "data_path = project_root / 'data' / 'raw' / 'friday_02_03_2018_combined_sample.csv'\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Loaded {len(df):,} records\")\n",
    "print(f\"Number of features: {len(df.columns)}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aae62fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 289799 entries, 0 to 289798\n",
      "Columns: 323 entries, flow_id to label\n",
      "dtypes: float64(259), int64(56), object(8)\n",
      "memory usage: 714.2+ MB\n",
      "None\n",
      "\n",
      "Missing values:\n",
      "payload_bytes_cov                  108358\n",
      "fwd_payload_bytes_cov               75401\n",
      "bwd_payload_bytes_cov               59023\n",
      "bwd_packets_IAT_skewness            49868\n",
      "bwd_packets_IAT_cov                 49868\n",
      "fwd_packets_IAT_cov                 34082\n",
      "fwd_packets_IAT_skewness            34027\n",
      "cov_payload_bytes_delta_len         28349\n",
      "cov_fwd_payload_bytes_delta_len     18905\n",
      "cov_bwd_payload_bytes_delta_len     15945\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check data types and missing values\n",
    "print(\"Data Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2891990f",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc02c177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 'label' as target variable\n",
      "\n",
      "Feature matrix shape: (289799, 322)\n",
      "Target shape: (289799,)\n",
      "\n",
      "Class distribution:\n",
      "label\n",
      "Benign    278864\n",
      "Bot        10935\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "# Identify the label column (could be 'label', 'Label', etc.)\n",
    "label_col = None\n",
    "for col in ['label', 'Label', 'label_name']:\n",
    "    if col in df.columns:\n",
    "        label_col = col\n",
    "        break\n",
    "\n",
    "if label_col is None:\n",
    "    raise ValueError(\"No label column found in dataset\")\n",
    "\n",
    "print(f\"Using '{label_col}' as target variable\")\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.drop(columns=[label_col])\n",
    "y = df[label_col]\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nClass distribution:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa5dbfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n",
      "\n",
      "Columns with missing values:\n",
      "payload_bytes_cov                  108358\n",
      "fwd_payload_bytes_cov               75401\n",
      "bwd_payload_bytes_cov               59023\n",
      "packets_IAT_cov                       437\n",
      "fwd_packets_IAT_skewness            34027\n",
      "fwd_packets_IAT_cov                 34082\n",
      "bwd_packets_IAT_skewness            49868\n",
      "bwd_packets_IAT_cov                 49868\n",
      "cov_packets_delta_time                437\n",
      "cov_bwd_packets_delta_time              1\n",
      "cov_fwd_packets_delta_time             55\n",
      "cov_packets_delta_len                5696\n",
      "cov_bwd_packets_delta_len            1398\n",
      "cov_fwd_packets_delta_len            3102\n",
      "cov_header_bytes_delta_len           7780\n",
      "cov_bwd_header_bytes_delta_len       1464\n",
      "cov_fwd_header_bytes_delta_len       4140\n",
      "cov_payload_bytes_delta_len         28349\n",
      "cov_bwd_payload_bytes_delta_len     15945\n",
      "cov_fwd_payload_bytes_delta_len     18905\n",
      "dtype: int64\n",
      "\n",
      "Remaining missing values: 0\n",
      "\n",
      "Final feature matrix shape: (289799, 322)\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "print(\"Handling missing values...\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_counts = X.isnull().sum()\n",
    "missing_cols = missing_counts[missing_counts > 0]\n",
    "\n",
    "if len(missing_cols) > 0:\n",
    "    print(f\"\\nColumns with missing values:\\n{missing_cols}\")\n",
    "    \n",
    "    # Strategy: Fill numeric columns with median, drop columns with >50% missing\n",
    "    threshold = 0.5\n",
    "    high_missing = missing_cols[missing_cols / len(X) > threshold]\n",
    "    \n",
    "    if len(high_missing) > 0:\n",
    "        print(f\"\\nDropping columns with >{threshold*100}% missing: {list(high_missing.index)}\")\n",
    "        X = X.drop(columns=high_missing.index)\n",
    "    \n",
    "    # Fill remaining missing values with median for numeric columns\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        if X[col].isnull().any():\n",
    "            X[col] = X[col].fillna(X[col].median())\n",
    "    \n",
    "    print(f\"\\nRemaining missing values: {X.isnull().sum().sum()}\")\n",
    "else:\n",
    "    print(\"No missing values found!\")\n",
    "\n",
    "print(f\"\\nFinal feature matrix shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2375d115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for infinite values...\n",
      "\n",
      "Replaced infinite values in 9 columns\n",
      "  cov_packets_delta_len: 998 infinite values\n",
      "  cov_bwd_packets_delta_len: 1093 infinite values\n",
      "  cov_fwd_packets_delta_len: 141 infinite values\n",
      "  cov_header_bytes_delta_len: 488 infinite values\n",
      "  cov_bwd_header_bytes_delta_len: 1102 infinite values\n",
      "  cov_fwd_header_bytes_delta_len: 63 infinite values\n",
      "  cov_payload_bytes_delta_len: 204435 infinite values\n",
      "  cov_bwd_payload_bytes_delta_len: 94260 infinite values\n",
      "  cov_fwd_payload_bytes_delta_len: 183487 infinite values\n"
     ]
    }
   ],
   "source": [
    "# Handle infinite values\n",
    "print(\"Checking for infinite values...\")\n",
    "\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "inf_counts = {}\n",
    "\n",
    "for col in numeric_cols:\n",
    "    inf_count = np.isinf(X[col]).sum()\n",
    "    if inf_count > 0:\n",
    "        inf_counts[col] = inf_count\n",
    "        # Replace inf with NaN, then fill with column median\n",
    "        X[col] = X[col].replace([np.inf, -np.inf], np.nan)\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "if inf_counts:\n",
    "    print(f\"\\nReplaced infinite values in {len(inf_counts)} columns\")\n",
    "    for col, count in list(inf_counts.items())[:10]:\n",
    "        print(f\"  {col}: {count} infinite values\")\n",
    "else:\n",
    "    print(\"No infinite values found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ade653e",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbc08614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating derived features...\n",
      "Found 104 forward features and 104 backward features\n",
      "\n",
      "Created 2 derived features\n",
      "\n",
      "Dropping 6 non-numeric columns:\n",
      "  - flow_id\n",
      "  - src_ip\n",
      "  - dst_ip\n",
      "  - protocol\n",
      "  - delta_start\n",
      "  - handshake_duration\n",
      "\n",
      "Final feature count: 317\n",
      "All features are numeric: True\n"
     ]
    }
   ],
   "source": [
    "# Create derived features if relevant columns exist\n",
    "print(\"Creating derived features...\")\n",
    "\n",
    "# Check if we have forward/backward packet columns\n",
    "fwd_cols = [c for c in X.columns if 'fwd' in c.lower()]\n",
    "bwd_cols = [c for c in X.columns if 'bwd' in c.lower()]\n",
    "\n",
    "print(f\"Found {len(fwd_cols)} forward features and {len(bwd_cols)} backward features\")\n",
    "\n",
    "# Example derived features (customize based on your data)\n",
    "derived_features = []\n",
    "\n",
    "# Add timestamp if you have it (for temporal features)\n",
    "if 'timestamp' in X.columns:\n",
    "    X['timestamp'] = pd.to_datetime(X['timestamp'])\n",
    "    X['hour'] = X['timestamp'].dt.hour\n",
    "    X['day_of_week'] = X['timestamp'].dt.dayofweek\n",
    "    derived_features.extend(['hour', 'day_of_week'])\n",
    "    X = X.drop(columns=['timestamp'])\n",
    "\n",
    "print(f\"\\nCreated {len(derived_features)} derived features\")\n",
    "\n",
    "# Drop non-numeric columns (like flow IDs, IP addresses, etc.)\n",
    "non_numeric_cols = X.select_dtypes(exclude=[np.number]).columns\n",
    "if len(non_numeric_cols) > 0:\n",
    "    print(f\"\\nDropping {len(non_numeric_cols)} non-numeric columns:\")\n",
    "    for col in non_numeric_cols:\n",
    "        print(f\"  - {col}\")\n",
    "    X = X.drop(columns=non_numeric_cols)\n",
    "\n",
    "print(f\"\\nFinal feature count: {X.shape[1]}\")\n",
    "print(f\"All features are numeric: {X.select_dtypes(include=[np.number]).shape[1] == X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17612787",
   "metadata": {},
   "source": [
    "## 4. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f502ed06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding target labels...\n",
      "\n",
      "Label mapping:\n",
      "  Benign: 0\n",
      "  Bot: 1\n",
      "\n",
      "Binary distribution (0=Benign, 1=Attack):\n",
      "label\n",
      "0    278864\n",
      "1     10935\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Encode target labels\n",
    "print(\"Encoding target labels...\")\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(f\"\\nLabel mapping:\")\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    print(f\"  {label}: {i}\")\n",
    "\n",
    "# Convert to binary if needed (benign vs attack)\n",
    "y_binary = (y != 'Benign').astype(int)\n",
    "print(f\"\\nBinary distribution (0=Benign, 1=Attack):\")\n",
    "print(pd.Series(y_binary).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc10e7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into train/test sets...\n",
      "Training set: (231839, 317)\n",
      "Test set: (57960, 317)\n",
      "\n",
      "Train class distribution:\n",
      "label\n",
      "0    223091\n",
      "1      8748\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test class distribution:\n",
      "label\n",
      "0    55773\n",
      "1     2187\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split data before scaling to prevent data leakage\n",
    "print(\"Splitting data into train/test sets...\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_binary, test_size=0.2, random_state=42, stratify=y_binary\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"\\nTrain class distribution:\\n{pd.Series(y_train).value_counts()}\")\n",
    "print(f\"\\nTest class distribution:\\n{pd.Series(y_test).value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f87ab8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling features...\n",
      "Scaled training set: (231839, 317)\n",
      "Scaled test set: (57960, 317)\n",
      "\n",
      "Sample of scaled features:\n",
      "        src_port  dst_port  duration  packets_count  fwd_packets_count  \\\n",
      "244091  1.081177 -0.496640 -0.153053      -0.017458          -0.019853   \n",
      "276234  0.906893 -0.324369 -0.122902      -0.004508          -0.007844   \n",
      "44106   0.412189 -0.517998  0.159728      -0.016019          -0.015850   \n",
      "214029  0.698676 -0.324369 -0.143853      -0.008825          -0.007844   \n",
      "177534  0.461436 -0.496757 -0.127762      -0.007386          -0.007844   \n",
      "\n",
      "        bwd_packets_count  total_payload_bytes  fwd_total_payload_bytes  \\\n",
      "244091          -0.015666            -0.012254                -0.049846   \n",
      "276234          -0.002562            -0.008791                 0.025153   \n",
      "44106           -0.015666            -0.012582                -0.076556   \n",
      "214029          -0.009114            -0.009333                 0.015863   \n",
      "177534          -0.006930            -0.007253                -0.052363   \n",
      "\n",
      "        bwd_total_payload_bytes  payload_bytes_max  ...  \\\n",
      "244091                -0.011491          -0.642664  ...   \n",
      "276234                -0.009194           0.602281  ...   \n",
      "44106                 -0.011402          -0.532993  ...   \n",
      "214029                -0.009592           0.573357  ...   \n",
      "177534                -0.006445           0.948166  ...   \n",
      "\n",
      "        max_fwd_payload_bytes_delta_len  mean_fwd_payload_bytes_delta_len  \\\n",
      "244091                        -0.314051                          2.401530   \n",
      "276234                         0.516079                         -0.120914   \n",
      "44106                         -0.387030                         -0.120914   \n",
      "214029                         0.340931                         -0.120914   \n",
      "177534                        -0.217355                         -0.120914   \n",
      "\n",
      "        mode_fwd_payload_bytes_delta_len  \\\n",
      "244091                          0.474607   \n",
      "276234                         -1.596685   \n",
      "44106                           0.618583   \n",
      "214029                         -1.282556   \n",
      "177534                         -0.003132   \n",
      "\n",
      "        variance_fwd_payload_bytes_delta_len  std_fwd_payload_bytes_delta_len  \\\n",
      "244091                             -0.024536                        -0.369440   \n",
      "276234                              0.010454                         0.764853   \n",
      "44106                              -0.024789                        -0.395760   \n",
      "214029                              0.000773                         0.562841   \n",
      "177534                             -0.021370                        -0.145939   \n",
      "\n",
      "        median_fwd_payload_bytes_delta_len  \\\n",
      "244091                           -0.028051   \n",
      "276234                           -0.069584   \n",
      "44106                            -0.069584   \n",
      "214029                           -0.069584   \n",
      "177534                           -0.069584   \n",
      "\n",
      "        skewness_fwd_payload_bytes_delta_len  cov_fwd_payload_bytes_delta_len  \\\n",
      "244091                              2.719003                        -0.015393   \n",
      "276234                             -0.704063                        -0.021445   \n",
      "44106                               0.236894                        -0.021445   \n",
      "214029                             -0.824382                        -0.021445   \n",
      "177534                              0.236894                        -0.021445   \n",
      "\n",
      "        hour  day_of_week  \n",
      "244091   0.0          0.0  \n",
      "276234   0.0          0.0  \n",
      "44106    0.0          0.0  \n",
      "214029   0.0          0.0  \n",
      "177534   0.0          0.0  \n",
      "\n",
      "[5 rows x 317 columns]\n"
     ]
    }
   ],
   "source": [
    "# Scale features using StandardScaler\n",
    "print(\"Scaling features...\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame to preserve column names\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(f\"Scaled training set: {X_train_scaled.shape}\")\n",
    "print(f\"Scaled test set: {X_test_scaled.shape}\")\n",
    "\n",
    "# Show sample of scaled data\n",
    "print(\"\\nSample of scaled features:\")\n",
    "print(X_train_scaled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a380f3",
   "metadata": {},
   "source": [
    "## 5. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba6fa309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed data...\n",
      "\n",
      "Processed data saved to: /Users/matthewweaver/Repositories/nidstream/data/processed\n",
      "Files created:\n",
      "  - X_train.csv\n",
      "  - X_test.csv\n",
      "  - y_train.csv\n",
      "  - y_test.csv\n",
      "  - scaler.pkl\n",
      "  - label_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save processed data\n",
    "print(\"Saving processed data...\")\n",
    "\n",
    "processed_dir = project_root / 'data' / 'processed'\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save train/test splits\n",
    "X_train_scaled.to_csv(processed_dir / 'X_train.csv', index=False)\n",
    "X_test_scaled.to_csv(processed_dir / 'X_test.csv', index=False)\n",
    "pd.Series(y_train, name='label').to_csv(processed_dir / 'y_train.csv', index=False)\n",
    "pd.Series(y_test, name='label').to_csv(processed_dir / 'y_test.csv', index=False)\n",
    "\n",
    "# Save scaler and label encoder for later use\n",
    "import joblib\n",
    "joblib.dump(scaler, processed_dir / 'scaler.pkl')\n",
    "joblib.dump(label_encoder, processed_dir / 'label_encoder.pkl')\n",
    "\n",
    "print(f\"\\nProcessed data saved to: {processed_dir}\")\n",
    "print(\"Files created:\")\n",
    "print(\"  - X_train.csv\")\n",
    "print(\"  - X_test.csv\")\n",
    "print(\"  - y_train.csv\")\n",
    "print(\"  - y_test.csv\")\n",
    "print(\"  - scaler.pkl\")\n",
    "print(\"  - label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12999b7",
   "metadata": {},
   "source": [
    "## 6. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73612f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FEATURE ENGINEERING SUMMARY\n",
      "============================================================\n",
      "\n",
      "Original dataset: 289,799 samples, 323 features\n",
      "Final feature count: 317\n",
      "\n",
      "Training set: 231,839 samples\n",
      "Test set: 57,960 samples\n",
      "\n",
      "Class distribution (train):\n",
      "  Benign: 223,091 (96.2%)\n",
      "  Attack: 8,748 (3.8%)\n",
      "\n",
      "Data ready for model training!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Summary of feature engineering process\n",
    "print(\"=\" * 60)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nOriginal dataset: {len(df):,} samples, {len(df.columns)} features\")\n",
    "print(f\"Final feature count: {X_train_scaled.shape[1]}\")\n",
    "print(f\"\\nTraining set: {len(X_train_scaled):,} samples\")\n",
    "print(f\"Test set: {len(X_test_scaled):,} samples\")\n",
    "print(f\"\\nClass distribution (train):\")\n",
    "print(f\"  Benign: {(y_train == 0).sum():,} ({(y_train == 0).sum() / len(y_train) * 100:.1f}%)\")\n",
    "print(f\"  Attack: {(y_train == 1).sum():,} ({(y_train == 1).sum() / len(y_train) * 100:.1f}%)\")\n",
    "print(f\"\\nData ready for model training!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c231c7",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "The processed data is now ready for:\n",
    "1. Model training in `03_model_training.ipynb`\n",
    "2. Hyperparameter tuning\n",
    "3. Model evaluation and comparison\n",
    "\n",
    "**Note:** You may want to:\n",
    "- Apply SMOTE or other techniques for class imbalance\n",
    "- Perform feature selection to reduce dimensionality\n",
    "- Experiment with different scaling methods\n",
    "- Create more domain-specific features based on network traffic analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nidstream",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
