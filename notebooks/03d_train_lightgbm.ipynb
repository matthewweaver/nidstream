{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbca1a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LightGBM available\n",
      "MLflow Tracking URI: file:./mlruns\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "from notebooks.training_utils import (\n",
    "    load_training_data, train_and_evaluate, save_models, \n",
    "    log_to_mlflow, print_summary\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Fix matplotlib backend issue with LightGBM in notebooks\n",
    "os.environ['MPLBACKEND'] = 'agg'\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    import mlflow\n",
    "    import mlflow.lightgbm\n",
    "    LIGHTGBM_AVAILABLE = True\n",
    "    print(\"✅ LightGBM available\")\n",
    "except ImportError as e:\n",
    "    LIGHTGBM_AVAILABLE = False\n",
    "    print(f\"⚠️  LightGBM not installed: {e}\")\n",
    "    print(\"    Install with: pip install lightgbm\")\n",
    "    print(\"    Skipping this notebook...\")\n",
    "\n",
    "# Setup MLflow\n",
    "if LIGHTGBM_AVAILABLE:\n",
    "    mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "    mlflow.set_experiment(\"network-intrusion-detection\")\n",
    "    print(f\"MLflow Tracking URI: {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a6bb0b",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80c9ae07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SMOTE training data...\n",
      "  Training set: (446182, 334)\n",
      "  Test set: (57960, 334)\n",
      "  Train class distribution: Benign=223091, Attack=223091\n",
      "Loading original training data...\n",
      "  Training set: (231839, 334)\n",
      "  Test set: (57960, 334)\n",
      "  Train class distribution: Benign=223091, Attack=8748\n",
      "Scale pos weight: 25.50\n"
     ]
    }
   ],
   "source": [
    "if LIGHTGBM_AVAILABLE:\n",
    "    # Load SMOTE data\n",
    "    X_train_smote, X_test, y_train_smote, y_test, project_root = load_training_data(use_smote=True)\n",
    "\n",
    "    # Load original data for scale_pos_weight strategy\n",
    "    X_train, _, y_train, _, _ = load_training_data(use_smote=False)\n",
    "\n",
    "    # Calculate scale_pos_weight\n",
    "    scale_pos_weight = np.sum(y_train == 0) / np.sum(y_train == 1)\n",
    "    print(f\"Scale pos weight: {scale_pos_weight:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db336e03",
   "metadata": {},
   "source": [
    "## 2. Train LightGBM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75e13251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING: LightGBM - SMOTE Strategy\n",
      "================================================================================\n",
      "✅ Training completed in 6.33 seconds\n",
      "\n",
      "Test Set Metrics:\n",
      "  accuracy: 1.0000\n",
      "  precision: 0.9995\n",
      "  recall: 1.0000\n",
      "  f1: 0.9998\n",
      "  roc_auc: 1.0000\n",
      "  pr_auc: 1.0000\n",
      "  train_time: 6.33s\n",
      "================================================================================\n",
      "TRAINING: LightGBM - Scale Pos Weight Strategy\n",
      "================================================================================\n",
      "✅ Training completed in 4.76 seconds\n",
      "\n",
      "Test Set Metrics:\n",
      "  accuracy: 1.0000\n",
      "  precision: 0.9995\n",
      "  recall: 1.0000\n",
      "  f1: 0.9998\n",
      "  roc_auc: 1.0000\n",
      "  pr_auc: 1.0000\n",
      "  train_time: 4.76s\n"
     ]
    }
   ],
   "source": [
    "if LIGHTGBM_AVAILABLE:\n",
    "    # SMOTE Strategy\n",
    "    lgb_smote = lgb.LGBMClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    lgb_smote, metrics_smote = train_and_evaluate(\n",
    "        lgb_smote, X_train_smote, y_train_smote, X_test, y_test,\n",
    "        \"LightGBM - SMOTE Strategy\"\n",
    "    )\n",
    "\n",
    "    # Scale Pos Weight Strategy\n",
    "    lgb_weighted = lgb.LGBMClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.1,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    lgb_weighted, metrics_weighted = train_and_evaluate(\n",
    "        lgb_weighted, X_train, y_train, X_test, y_test,\n",
    "        \"LightGBM - Scale Pos Weight Strategy\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813cfe05",
   "metadata": {},
   "source": [
    "## 3. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd80c30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: /Users/matthewweaver/Repositories/nidstream/models/lgb_smote.pkl\n",
      "✅ Saved: /Users/matthewweaver/Repositories/nidstream/models/lgb_weighted.pkl\n",
      "✅ Saved metrics: /Users/matthewweaver/Repositories/nidstream/models/lgb_metrics.pkl\n"
     ]
    }
   ],
   "source": [
    "if LIGHTGBM_AVAILABLE:\n",
    "    save_models(lgb_smote, lgb_weighted, metrics_smote, metrics_weighted, 'lgb', project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5528596",
   "metadata": {},
   "source": [
    "## 4. Log to MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce1251ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging LGB_SMOTE to MLflow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/09 13:24:59 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/09 13:25:01 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2026/01/09 13:25:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2026/01/09 13:25:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ Run ID: b3777fdcba8447b2a8a382c44a5f2c06\n",
      "Logging LGB_ScalePosWeight to MLflow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/09 13:25:02 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2026/01/09 13:25:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ Run ID: 6c988f2658e14938bb858e2a9ba76006\n",
      "\n",
      "✅ All models logged to MLflow\n"
     ]
    }
   ],
   "source": [
    "if LIGHTGBM_AVAILABLE:\n",
    "    # Log SMOTE model\n",
    "    log_to_mlflow(\n",
    "        lgb_smote, metrics_smote, \"LGB_SMOTE\", \"LightGBM\", \"SMOTE\",\n",
    "        {\"n_estimators\": 100, \"max_depth\": 10, \"learning_rate\": 0.1},\n",
    "        X_train_smote, X_test, y_train_smote,\n",
    "        mlflow.lightgbm\n",
    "    )\n",
    "\n",
    "    # Log Weighted model\n",
    "    log_to_mlflow(\n",
    "        lgb_weighted, metrics_weighted, \"LGB_ScalePosWeight\", \"LightGBM\", \"Scale_Pos_Weight\",\n",
    "        {\"n_estimators\": 100, \"max_depth\": 10, \"learning_rate\": 0.1, \"scale_pos_weight\": float(scale_pos_weight)},\n",
    "        X_train, X_test, y_train,\n",
    "        mlflow.lightgbm\n",
    "    )\n",
    "\n",
    "    print(\"\\n✅ All models logged to MLflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0f06b1",
   "metadata": {},
   "source": [
    "## 5. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6877740b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LIGHTGBM TRAINING COMPLETE\n",
      "================================================================================\n",
      "\n",
      "SMOTE Strategy:\n",
      "  PR-AUC: 1.0000\n",
      "  F1 Score: 0.9998\n",
      "  Recall: 1.0000\n",
      "\n",
      "Class Weight Strategy:\n",
      "  PR-AUC: 1.0000\n",
      "  F1 Score: 0.9998\n",
      "  Recall: 1.0000\n",
      "\n",
      "✅ Better strategy for LightGBM: SMOTE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "if LIGHTGBM_AVAILABLE:\n",
    "    print_summary(metrics_smote, metrics_weighted, \"LightGBM\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nidstream",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
